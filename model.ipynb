{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import math\n", "import torch\n", "from torch import nn\n", "from torch.nn import functional as F"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import commons\n", "import modules\n", "import attentions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from torch.nn import Conv1d, ConvTranspose1d, Conv2d\n", "from torch.nn.utils import weight_norm, remove_weight_norm, spectral_norm"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from commons import init_weights, get_padding"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TextEncoder(nn.Module):\n", "\tdef __init__(self,\n", "\t\t\tn_vocab,\n", "\t\t\tout_channels,\n", "\t\t\thidden_channels,\n", "\t\t\tfilter_channels,\n", "\t\t\tn_heads,\n", "\t\t\tn_layers,\n", "\t\t\tkernel_size,\n", "\t\t\tp_dropout):\n", "\t\tsuper().__init__()\n", "\t\tself.n_vocab = n_vocab\n", "\t\tself.out_channels = out_channels\n", "\t\tself.hidden_channels = hidden_channels\n", "\t\tself.filter_channels = filter_channels\n", "\t\tself.n_heads = n_heads\n", "\t\tself.n_layers = n_layers\n", "\t\tself.kernel_size = kernel_size\n", "\t\tself.p_dropout = p_dropout"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tself.emb = nn.Embedding(n_vocab, hidden_channels)\n", "\t\tnn.init.normal_(self.emb.weight, 0.0, hidden_channels**-0.5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tself.encoder = attentions.Encoder(\n", "\t\t\thidden_channels,\n", "\t\t\tfilter_channels,\n", "\t\t\tn_heads,\n", "\t\t\tn_layers,\n", "\t\t\tkernel_size,\n", "\t\t\tp_dropout)\n", "\t\tself.proj= nn.Conv1d(hidden_channels, out_channels * 2, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tdef forward(self, x, x_lengths):\n", "\t\tx = self.emb(x) * math.sqrt(self.hidden_channels) # [b, t, h]\n", "\t\tx = torch.transpose(x, 1, -1) # [b, h, t]\n", "\t\tx_mask = torch.unsqueeze(commons.sequence_mask(x_lengths, x.size(2)), 1).to(x.dtype)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tx = self.encoder(x * x_mask, x_mask)\n", "\t\tstats = self.proj(x) * x_mask"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tm, logs = torch.split(stats, self.out_channels, dim=1)\n", "\t\treturn x, m, logs, x_mask\n", "     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class DurationPredictor(nn.Module):\n", "    def __init__(\n", "        self, in_channels, filter_channels, kernel_size, p_dropout, gin_channels=0\n", "    ):\n", "        super().__init__()\n", "        self.in_channels = in_channels\n", "        self.filter_channels = filter_channels\n", "        self.kernel_size = kernel_size\n", "        self.p_dropout = p_dropout\n", "        self.gin_channels = gin_channels\n", "        self.drop = nn.Dropout(p_dropout)\n", "        self.conv_1 = nn.Conv1d(\n", "            in_channels, filter_channels, kernel_size, padding=kernel_size // 2\n", "        )\n", "        self.norm_1 = modules.LayerNorm(filter_channels)\n", "        self.conv_2 = nn.Conv1d(\n", "            filter_channels, filter_channels, kernel_size, padding=kernel_size // 2\n", "        )\n", "        self.norm_2 = modules.LayerNorm(filter_channels)\n", "        self.proj = nn.Conv1d(filter_channels, 1, 1)\n", "        if gin_channels != 0:\n", "            self.cond = nn.Conv1d(gin_channels, in_channels, 1)\n", "    def forward(self, x, x_mask, g=None):\n", "        x = torch.detach(x)\n", "        if g is not None:\n", "            g = torch.detach(g)\n", "            x = x + self.cond(g)\n", "        x = self.conv_1(x * x_mask)\n", "        x = torch.relu(x)\n", "        x = self.norm_1(x)\n", "        x = self.drop(x)\n", "        x = self.conv_2(x * x_mask)\n", "        x = torch.relu(x)\n", "        x = self.norm_2(x)\n", "        x = self.drop(x)\n", "        x = self.proj(x * x_mask)\n", "        return x * x_mask\n", "               \n", "class StochasticDurationPredictor(nn.Module):\n", "\tdef __init__(self, in_channels, filter_channels, kernel_size, p_dropout, n_flows=4, gin_channels=0):\n", "\t\tsuper().__init__()\n", "\t\tfilter_channels = in_channels # it needs to be removed from future version.\n", "\t\tself.in_channels = in_channels\n", "\t\tself.filter_channels = filter_channels\n", "\t\tself.kernel_size = kernel_size\n", "\t\tself.p_dropout = p_dropout\n", "\t\tself.n_flows = n_flows\n", "\t\tself.gin_channels = gin_channels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tself.log_flow = modules.Log()\n", "\t\tself.flows = nn.ModuleList()\n", "\t\tself.flows.append(modules.ElementwiseAffine(2))\n", "\t\tfor i in range(n_flows):\n", "\t\t\tself.flows.append(modules.ConvFlow(2, filter_channels, kernel_size, n_layers=3))\n", "\t\t\tself.flows.append(modules.Flip())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tself.post_pre = nn.Conv1d(1, filter_channels, 1)\n", "\t\tself.post_proj = nn.Conv1d(filter_channels, filter_channels, 1)\n", "\t\tself.post_convs = modules.DDSConv(filter_channels, kernel_size, n_layers=3, p_dropout=p_dropout)\n", "\t\tself.post_flows = nn.ModuleList()\n", "\t\tself.post_flows.append(modules.ElementwiseAffine(2))\n", "\t\tfor i in range(4):\n", "\t\t\tself.post_flows.append(modules.ConvFlow(2, filter_channels, kernel_size, n_layers=3))\n", "\t\t\tself.post_flows.append(modules.Flip())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tself.pre = nn.Conv1d(in_channels, filter_channels, 1)\n", "\t\tself.proj = nn.Conv1d(filter_channels, filter_channels, 1)\n", "\t\tself.convs = modules.DDSConv(filter_channels, kernel_size, n_layers=3, p_dropout=p_dropout)\n", "\t\tif gin_channels != 0:\n", "\t\t\tself.cond = nn.Conv1d(gin_channels, filter_channels, 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tdef forward(self, x, x_mask, w=None, g=None, reverse=False, noise_scale=1.0):\n", "\t\tx = torch.detach(x)\n", "\t\tx = self.pre(x)\n", "\t\tif g is not None:\n", "\t\t\tg = torch.detach(g)\n", "\t\t\tx = x + self.cond(g)\n", "\t\tx = self.convs(x, x_mask)\n", "\t\tx = self.proj(x) * x_mask"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tif not reverse:\n", "\t\t\tflows = self.flows\n", "\t\t\tassert w is not None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\tlogdet_tot_q = 0\n", "\t\t\th_w = self.post_pre(w)\n", "\t\t\th_w = self.post_convs(h_w, x_mask)\n", "\t\t\th_w = self.post_proj(h_w) * x_mask\n", "\t\t\te_q = torch.randn(w.size(0), 2, w.size(2)).to(device=x.device, dtype=x.dtype) * x_mask\n", "\t\t\tz_q = e_q\n", "\t\t\tfor flow in self.post_flows:\n", "\t\t\t\tz_q, logdet_q = flow(z_q, x_mask, g=(x + h_w))\n", "\t\t\t\tlogdet_tot_q += logdet_q\n", "\t\t\tz_u, z1 = torch.split(z_q, [1, 1], 1)\n", "\t\t\tu = torch.sigmoid(z_u) * x_mask\n", "\t\t\tz0 = (w - u) * x_mask\n", "\t\t\tlogdet_tot_q += torch.sum((F.logsigmoid(z_u) + F.logsigmoid(-z_u)) * x_mask, [1,2])\n", "\t\t\tlogq = torch.sum(-0.5 * (math.log(2*math.pi) + (e_q**2)) * x_mask, [1,2]) - logdet_tot_q"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\tlogdet_tot = 0\n", "\t\t\tz0, logdet = self.log_flow(z0, x_mask)\n", "\t\t\tlogdet_tot += logdet\n", "\t\t\tz = torch.cat([z0, z1], 1)\n", "\t\t\tfor flow in flows:\n", "\t\t\t\tz, logdet = flow(z, x_mask, g=x, reverse=reverse)\n", "\t\t\t\tlogdet_tot = logdet_tot + logdet\n", "\t\t\tnll = torch.sum(0.5 * (math.log(2*math.pi) + (z**2)) * x_mask, [1,2]) - logdet_tot\n", "\t\t\treturn nll + logq # [b]\n", "\t\telse:\n", "\t\t\tflows = list(reversed(self.flows))\n", "\t\t\tflows = flows[:-2] + [flows[-1]] # remove a useless vflow\n", "\t\t\tz = torch.randn(x.size(0), 2, x.size(2)).to(device=x.device, dtype=x.dtype) * noise_scale\n", "\t\t\tfor flow in flows:\n", "\t\t\t\tz = flow(z, x_mask, g=x, reverse=reverse)\n", "\t\t\tz0, z1 = torch.split(z, [1, 1], 1)\n", "\t\t\tlogw = z0\n", "\t\t\treturn logw"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class PosteriorEncoder(nn.Module):\n", "    def __init__(\n", "        self,\n", "        in_channels,\n", "        out_channels,\n", "        hidden_channels,\n", "        kernel_size,\n", "        dilation_rate,\n", "        n_layers,\n", "        gin_channels=0,\n", "    ):\n", "        super().__init__()\n", "        self.in_channels = in_channels\n", "        self.out_channels = out_channels\n", "        self.hidden_channels = hidden_channels\n", "        self.kernel_size = kernel_size\n", "        self.dilation_rate = dilation_rate\n", "        self.n_layers = n_layers\n", "        self.gin_channels = gin_channels\n", "        self.pre = nn.Conv1d(in_channels, hidden_channels, 1)\n", "        self.enc = modules.WN(\n", "            hidden_channels,\n", "            kernel_size,\n", "            dilation_rate,\n", "            n_layers,\n", "            gin_channels=gin_channels,\n", "        )\n", "        self.proj = nn.Conv1d(hidden_channels, out_channels * 2, 1)\n", "    def forward(self, x, x_lengths, g=None, tau=1.0):\n", "        x_mask = torch.unsqueeze(commons.sequence_mask(x_lengths, x.size(2)), 1).to(\n", "            x.dtype\n", "        )\n", "        x = self.pre(x) * x_mask\n", "        x = self.enc(x, x_mask, g=g)\n", "        stats = self.proj(x) * x_mask\n", "        m, logs = torch.split(stats, self.out_channels, dim=1)\n", "        z = (m + torch.randn_like(m) * tau * torch.exp(logs)) * x_mask\n", "        return z, m, logs, x_mask"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Generator(torch.nn.Module):\n", "    def __init__(\n", "        self,\n", "        initial_channel,\n", "        resblock,\n", "        resblock_kernel_sizes,\n", "        resblock_dilation_sizes,\n", "        upsample_rates,\n", "        upsample_initial_channel,\n", "        upsample_kernel_sizes,\n", "        gin_channels=0,\n", "    ):\n", "        super(Generator, self).__init__()\n", "        self.num_kernels = len(resblock_kernel_sizes)\n", "        self.num_upsamples = len(upsample_rates)\n", "        self.conv_pre = Conv1d(\n", "            initial_channel, upsample_initial_channel, 7, 1, padding=3\n", "        )\n", "        resblock = modules.ResBlock1 if resblock == \"1\" else modules.ResBlock2\n", "        self.ups = nn.ModuleList()\n", "        for i, (u, k) in enumerate(zip(upsample_rates, upsample_kernel_sizes)):\n", "            self.ups.append(\n", "                weight_norm(\n", "                    ConvTranspose1d(\n", "                        upsample_initial_channel // (2**i),\n", "                        upsample_initial_channel // (2 ** (i + 1)),\n", "                        k,\n", "                        u,\n", "                        padding=(k - u) // 2,\n", "                    )\n", "                )\n", "            )\n", "        self.resblocks = nn.ModuleList()\n", "        for i in range(len(self.ups)):\n", "            ch = upsample_initial_channel // (2 ** (i + 1))\n", "            for j, (k, d) in enumerate(\n", "                zip(resblock_kernel_sizes, resblock_dilation_sizes)\n", "            ):\n", "                self.resblocks.append(resblock(ch, k, d))\n", "        self.conv_post = Conv1d(ch, 1, 7, 1, padding=3, bias=False)\n", "        self.ups.apply(init_weights)\n", "        if gin_channels != 0:\n", "            self.cond = nn.Conv1d(gin_channels, upsample_initial_channel, 1)\n", "    def forward(self, x, g=None):\n", "        x = self.conv_pre(x)\n", "        if g is not None:\n", "            x = x + self.cond(g)\n", "        for i in range(self.num_upsamples):\n", "            x = F.leaky_relu(x, modules.LRELU_SLOPE)\n", "            x = self.ups[i](x)\n", "            xs = None\n", "            for j in range(self.num_kernels):\n", "                if xs is None:\n", "                    xs = self.resblocks[i * self.num_kernels + j](x)\n", "                else:\n", "                    xs += self.resblocks[i * self.num_kernels + j](x)\n", "            x = xs / self.num_kernels\n", "        x = F.leaky_relu(x)\n", "        x = self.conv_post(x)\n", "        x = torch.tanh(x)\n", "        return x\n", "    def remove_weight_norm(self):\n", "        print(\"Removing weight norm...\")\n", "        for layer in self.ups:\n", "            remove_weight_norm(layer)\n", "        for layer in self.resblocks:\n", "            layer.remove_weight_norm()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ReferenceEncoder(nn.Module):\n", "    \"\"\"\n", "    inputs --- [N, Ty/r, n_mels*r]  mels\n", "    outputs --- [N, ref_enc_gru_size]\n", "    \"\"\"\n", "    def __init__(self, spec_channels, gin_channels=0, layernorm=True):\n", "        super().__init__()\n", "        self.spec_channels = spec_channels\n", "        ref_enc_filters = [32, 32, 64, 64, 128, 128]\n", "        K = len(ref_enc_filters)\n", "        filters = [1] + ref_enc_filters\n", "        convs = [\n", "            weight_norm(\n", "                nn.Conv2d(\n", "                    in_channels=filters[i],\n", "                    out_channels=filters[i + 1],\n", "                    kernel_size=(3, 3),\n", "                    stride=(2, 2),\n", "                    padding=(1, 1),\n", "                )\n", "            )\n", "            for i in range(K)\n", "        ]\n", "        self.convs = nn.ModuleList(convs)\n", "        out_channels = self.calculate_channels(spec_channels, 3, 2, 1, K)\n", "        self.gru = nn.GRU(\n", "            input_size=ref_enc_filters[-1] * out_channels,\n", "            hidden_size=256 // 2,\n", "            batch_first=True,\n", "        )\n", "        self.proj = nn.Linear(128, gin_channels)\n", "        if layernorm:\n", "            self.layernorm = nn.LayerNorm(self.spec_channels)\n", "        else:\n", "            self.layernorm = None\n", "    def forward(self, inputs, mask=None):\n", "        N = inputs.size(0)\n", "        out = inputs.view(N, 1, -1, self.spec_channels)  # [N, 1, Ty, n_freqs]\n", "        if self.layernorm is not None:\n", "            out = self.layernorm(out)\n", "        for conv in self.convs:\n", "            out = conv(out)\n", "            # out = wn(out)\n", "            out = F.relu(out)  # [N, 128, Ty//2^K, n_mels//2^K]\n", "        out = out.transpose(1, 2)  # [N, Ty//2^K, 128, n_mels//2^K]\n", "        T = out.size(1)\n", "        N = out.size(0)\n", "        out = out.contiguous().view(N, T, -1)  # [N, Ty//2^K, 128*n_mels//2^K]\n", "        self.gru.flatten_parameters()\n", "        memory, out = self.gru(out)  # out --- [1, N, 128]\n", "        return self.proj(out.squeeze(0))\n", "    def calculate_channels(self, L, kernel_size, stride, pad, n_convs):\n", "        for i in range(n_convs):\n", "            L = (L - kernel_size + 2 * pad) // stride + 1\n", "        return L"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}